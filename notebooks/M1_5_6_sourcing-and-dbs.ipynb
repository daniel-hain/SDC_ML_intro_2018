{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIs and Databases\n",
    "## A very superficial intro\n",
    "\n",
    "In this notebook we will explore how we can get data using APIs as well as where/how this data can be stored and processed.\n",
    "\n",
    "We will look at the following technologies:\n",
    "\n",
    "The requests library to work with REST APIs\n",
    "JSON - the most commonly used format for *unstructured* data (don't confuse with unstructured as in text or images)\n",
    "MongoDB - a popular NoSQL that natively handles JSON type data (we will be using MLab in the cloud rather than a local installation)\n",
    "\n",
    "Finally we will also have a look at SQL. For better or worse SQL type databases are still around and will be around in the foreseable future. Therefore, we need to get some basics.\n",
    "\n",
    "**For this tutorial we will need access to a MongoDB instance**\n",
    "\n",
    "If you like to use it you can install the free [MongoDB community edition on your machine](https://docs.mongodb.com/manual/administration/install-community/)\n",
    "\n",
    "However, it is much much easier and faster (for now) to use a hosted online version. You can get 500mb free space to play around from mLab https://mlab.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import json\n",
    "import time, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "# c = MongoClient() if you connect locally\n",
    "\n",
    "# Please enter your credentials in the different fields\n",
    "connection = MongoClient('ds149672.mlab.com', 49672)\n",
    "db = connection['sds-teaching']\n",
    "db.authenticate('sds', 'sdsaau2018')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MongoDB\n",
    "MongoDB is as mentioned NoSQL which means that it uses a hierarchical structure format (for the lack of a better expression). It stores BSON (binary JSON files) as so called documents within collections within Databases.\n",
    "Why is that great?\n",
    "\n",
    "There is no schema and you can basically drop arbitrary JSON chunks into a MongoDB collection\n",
    "\n",
    "![](https://docs.mongodb.com/manual/_images/data-model-denormalized.bakedsvg.svg)\n",
    "\n",
    "JSON data is overall equal to Python dictionaries and thus collections of key-value pairs with nested other dictionaries and/or lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requests\n",
    "\n",
    "The requests library allows us to interact with APIs by making GET or POST calls. Every time you post something on e.g. Facebook, your phone is making a POST requests to and Facebook API endpoint sending the text or picture along with some metadata. When obtaining data we mostly use GET requests (which is kind of logical). Actually we can use the requests GET with any kind of URL, and will receive whatever is hiding behind this URL (usually some HTML output) sent back by the server.\n",
    "\n",
    "Note, that recurrent requests are heavy on servers and generate traffic. People runnig pages don not like that. Therefore, be nice and build in some sleep-timers into your loops when running many requests on some page. OR THE'LL BAN YOU!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rq.get('https://nomadlist.com/@trevorgerhardt.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json = json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(response_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response_json.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's bring our data into MongoDB\n",
    "\n",
    "Most important commands for you:\n",
    "\n",
    "\n",
    "```\n",
    "collection = db.collection\n",
    "\n",
    "collection.insert_one(some_dict)\n",
    "collection.insert_many(sequence of dicts) # you can also pass a pandas dataframe as a list of dictionaries with .to_dict() attached\n",
    "\n",
    "collection.count\n",
    "\n",
    "collection.find_one()\n",
    "\n",
    "cursor = collection.find()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll create a new collection\n",
    "people1 = db.people1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And put in the parsed JSON\n",
    "people1.insert_one(response_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is it in there?\n",
    "\n",
    "people1.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some more data in and automize the \"harvesting\"\n",
    "We can for example extract the list of all followers of our initial person\n",
    "Turns out the uuids can also be used in the Nomadlist API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a list of ids of people that we would like to take out of the DB\n",
    "harvestlist = response_json['followers'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A API friendly loop to extract the data for our 40 people\n",
    "\n",
    "for i in harvestlist:\n",
    "    q = 'https://nomadlist.com/'+str(i)+'.json' # contructs the query for the GET call\n",
    "    res = rq.get(q) # grab the data form the API\n",
    "    if res.status_code in [502,404]: # securety measures. Continue the loop in case an error pops up\n",
    "        continue\n",
    "    people1.insert_one(json.loads(res.content)) # put the data into the DB\n",
    "    time.sleep(random.uniform(0.5,1)) # chill between 0.5 and 1 sec. Primitively simulate human behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people1.count() #did it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = people1.find() # Now we have the data we can take it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can be a bit more selective\n",
    "cursor = people1.find({'location.now.country':'Indonesia'},{'_id':0,'username':1,'stats':1}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the query construction in mongo is very different from what you have seen in Python or R or what you'll find in SQL. It is all {} and not really nice. But that is to some extent due to the fact that Mongo is mostly by machines for machines. Something you'll have to learn (and/or look up) if you want to work with MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pandas DF from a Mongo cursor is however not difficult.\n",
    "indonesia_df = pd.DataFrame(list(cursor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can also unpack nested dictionaries (here the stats column)\n",
    "pd.DataFrame([x[1] for x in indonesia_df.stats.iteritems()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mongo has many integrated complex functions for working with \"BigData\". Why not inside Pandas? A database will handle data on disk rather than in memory, index things for fast access and much more. \n",
    "\n",
    "One really useful but unfortunately complex (I have to look it up every time I use it) is aggregation of nested elements. \n",
    "\n",
    "MongoDB works with so called aggregation pipelines with a killer syntax :-/ \n",
    "\n",
    "In the following we will try to unpack or \"unwind\" the trips that are nested within every user-document. Why would we do that? Because you would like to analyse travel behavior on the micro level (individual trips).\n",
    "Want to know more? https://docs.mongodb.com/manual/reference/operator/aggregation-pipeline/\n",
    "\n",
    "Below we will create one of these pipelines combining match (a filtering function), project (for selecting what should be returned) and unwind (for disaggregation of nested arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return only trips of people that are in Indonesia at the moment (strange query but not wrong)\n",
    "cursor = people1.aggregate([{'$match':{'location.now.country':'Indonesia'}},\n",
    "                            {'$project':{'_id':0,'username':1,'trips':1}},\n",
    "                            {'$unwind':'$trips'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or just return all trips\n",
    "cursor = people1.aggregate([{'$project':{'_id':0,'username':1,'trips':1}},\n",
    "                            {'$unwind':'$trips'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(cursor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately we cannot pass this directly to pandas and will have to unpack a bit using a simple loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Unpacking the returned documents. Basically we just need to enter the \"trips\" key. We also add the username.\n",
    "trips = []\n",
    "while cursor:\n",
    "    doc = cursor.next()\n",
    "    trip = doc['trips']\n",
    "    trip['username'] = doc['username']\n",
    "    trips.append(trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can create a dataframe\n",
    "trips_df = pd.DataFrame(trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving on to SQL\n",
    "\n",
    "We will be using SQLite, a very simple SQL database (often used in mobile devices). Not as powerful as PosgreSQL or MySQL but easier to work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to import the sqlite driver\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection and create a DB file on disk\n",
    "db = sqlite3.connect('db_training.db', check_same_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can actually write directly from Pandas to SQL\n",
    "\n",
    "trips_df[['country', 'country_code', 'country_slug', 'date_end', 'date_start',\n",
    "       'epoch_end', 'epoch_start', 'latitude', 'length', 'longitude', 'place', 'place_photo', 'place_slug', 'place_url',\n",
    "       'user_photo', 'username']].to_sql('trips', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's read a bit manually\n",
    "# First we find out which tables we can ses in the connected DB\n",
    "cursor = db.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find trips to Indonesia\n",
    "\n",
    "cursor = db.cursor()\n",
    "cursor.execute(\"\"\"SELECT * FROM trips where country = 'Indonesia'\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can pass the cursor directly to Pandas (similar to MongoDB)\n",
    "indonesia_df1 = pd.DataFrame(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indonesia_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also ask pandas to perform the query for us\n",
    "indonesia_df2 = pd.read_sql_query(\"\"\"SELECT * FROM trips where country = 'Indonesia'\"\"\", db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indonesia_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If you want to learn more about working with SQL: https://www.dataquest.io/blog/python-pandas-databases/\n",
    "- There is also a great intro course on Datacamp: https://www.datacamp.com/courses/intro-to-sql-for-data-science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a cursor object\n",
    "cursor = db.cursor()\n",
    "cursor.execute('''\n",
    "    CREATE TABLE trips_mapping('index' INTEGER PRIMARY KEY, place_slug TEXT)\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indonesia_df.iterrows():\n",
    "    insert = i[1][['index','place_slug']]\n",
    "    cursor.execute('''INSERT INTO trips_mapping('index', place_slug) VALUES(?,?)''', tuple(insert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"\"\"SELECT * FROM trips_mapping\"\"\", db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close DB when finished\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
